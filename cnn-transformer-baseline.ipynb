{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New baseline for the bovine with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspired from this guide :\n",
    "https://keras.io/examples/vision/video_transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data, get_test_data, WeightedClassificationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#CPU\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  \n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 1024 #nbr of feat output by densenet121\n",
    "IMG_SIZE = 224\n",
    "NB_FRAMES=30 #2.56gb vs 0.33gb\n",
    "\n",
    "EPOCHS = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_train, labels_train = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_classifier= np.array(videos_train)\n",
    "y_for_classifier= labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_test, labels_test  = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_for_classifier = np.array(videos_test)\n",
    "ytest_for_classifier = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_frames(video, new_size):\n",
    "    res=[]\n",
    "    for frame in video:\n",
    "        resized_img=Image.fromarray(frame).resize(size=(224, 224))\n",
    "        res.append(np.array(resized_img))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that gets all dataset\n",
    "# 30 frames per video for 177 video = 2.65 gb !if considering each frame of float64\n",
    "# as uint8 it takes 0.33 gb\n",
    "\n",
    "def gen_videos(videolist):\n",
    "    newvideos=[] # 177*30*250*250\n",
    "    for video in videolist:\n",
    "        reducedvideo= video.read_samples(video.frame_times[0:299:10])\n",
    "        reducedvideo= reducedvideo.astype('uint8')\n",
    "        #add dimnesion this takes quite a bit of memory ???? dim= 30*250*250*3\n",
    "        reducedvideo=np.repeat(reducedvideo[...,np.newaxis], 3, -1)\n",
    "        \n",
    "        #CROP from 250 to 224()DenseNet121 standards !! TODO !\n",
    "        reducedvideo=resize_frames(reducedvideo)\n",
    "        #and add a batch dimension. dim= 1*30*250*250*3\n",
    "        #reducedvideo = reducedvideo[None, ...]\n",
    "\n",
    "        newvideos.append(reducedvideo)\n",
    "    return newvideos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 30, 224, 224, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_for_classifier= np.array(gen_videos(X_for_classifier))\n",
    "X_for_classifier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 30, 224, 224, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_for_classifier= np.array(gen_videos(Xtest_for_classifier))\n",
    "Xtest_for_classifier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_int(argument):\n",
    "    switcher = {\n",
    "        'A':0,\n",
    "        'B':1,\n",
    "        'C':2,\n",
    "        'D':3,\n",
    "        'E':4,\n",
    "        'F':5,\n",
    "        'G':6,\n",
    "        'H':7,\n",
    "    }\n",
    " \n",
    "    # get() method of dictionary data type returns\n",
    "    # value of passed argument if it is present\n",
    "    # in dictionary otherwise second argument will\n",
    "    # be assigned as default value of passed argument\n",
    "    return switcher.get(argument, \"nothing\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "func=np.vectorize(class_to_int)\n",
    "#Train\n",
    "train_labels=func(y_for_classifier)\n",
    "#Test\n",
    "test_labels=func(ytest_for_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 0, 5, 7, 0, 0, 5, 5, 0, 2, 1, 2, 5, 7, 5, 5, 7, 1, 1, 7, 2,\n",
       "       7, 1, 1, 5, 7, 7, 7, 2, 2, 4, 6, 3, 4, 2, 0, 0, 7, 7, 6, 2, 5, 2,\n",
       "       6, 1, 7, 7, 7, 2, 7, 7, 7, 6, 0, 6, 0, 5, 4, 0, 5, 6, 5, 4, 5, 4,\n",
       "       5, 0, 1, 0, 6, 4, 6, 5, 6, 1, 1, 4, 5, 5, 1, 6, 5, 3, 1, 0, 3, 6,\n",
       "       3, 5, 5, 2, 1, 6, 2, 2, 2, 3, 6, 1, 0, 0, 5, 2, 2, 1, 2, 1, 3, 5,\n",
       "       6, 4, 1, 2, 1, 3, 3, 1, 0, 7, 7, 5, 7, 7, 7, 5, 7, 6, 4, 5, 0, 7,\n",
       "       6, 7, 5, 7, 7, 6, 1, 1, 7, 7, 6, 5, 7, 7, 4, 5, 7, 5, 5, 7, 5, 5,\n",
       "       5, 7, 7, 6, 0, 7, 1, 7, 6, 7, 6, 0, 7, 7, 7, 7, 4, 1, 2, 6, 7, 3,\n",
       "       3])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 6, 0, 5, 2, 7, 2, 2, 7, 7, 5, 7, 7, 4, 4, 4, 2, 2, 6, 7, 7,\n",
       "       7, 4, 6, 4, 3, 3, 6, 6, 5, 6, 4, 2, 4, 0, 4, 4, 2, 6, 6, 4, 0, 3,\n",
       "       3, 3, 0, 0, 5, 2, 1, 5, 2, 1, 1, 1, 2, 4, 4, 1, 4, 3, 6, 4, 1, 6,\n",
       "       4, 3, 3, 3, 0, 4, 4, 2, 6, 7, 7, 7, 5, 7, 6, 1, 5, 7, 7, 6, 6, 4,\n",
       "       2, 7, 0, 0, 7, 1, 6, 6, 7, 4, 3, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Build the feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.DenseNet121(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.densenet.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 955ms/step\n"
     ]
    }
   ],
   "source": [
    "f1=feature_extractor.predict(X_for_classifier[1][1][None,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(f1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAAOCAYAAACM5c9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADSklEQVR4nO3aQU/qWBjG8f9py6XQFigJJDTSmLgy0bDXpSs+rPFLYNgaxYWuRDGxIkVRCpTSzmJiM97ruGQW8/42pD0nPe95W55FU5VlGUIIIbZD+68LEEKI/xMJXSGE2CIJXSGE2CIJXSGE2CIJXSGE2CLjp0GlVKZpGkopNpsNAK7r8vb2RpqmX+YWCgWSJAHguy8ilFI/jimlSNMUwzDy6+i6TpqmeJ5HGIYsFosvcz9rA9A0La/R8zyWyyVhGJKmKdVqldlshlIKwzBI05TNZpPXopT6oy6lFKZpslgs/m6UYVCv13l5eflj74Zh0Gw2sW2b29vbn1qKpmn5Wp+//zyn6/qX/W82GzRNwzRN0jRlvV6z2WzysU+fx9/1L8uyvFefx7/v+/j4mPPzc5RS1Go1ptPpt/Xrug7wZe3f16rVahSLRYIgAKBcLrNYLL702LIsVqsVSZJgWRZJkrBarX7sHYBt2+i6znK5xLIs6vU6QRDk1yqVSvm47/sEQUCz2cznWJZFHMecnJxwcXFBlmWkaYppmtzf36PrOnEc4zgOrVaLyWSCbdtEUcR0OuXXr1/ouk6hUGA6neL7Po+PjxiGge/73N3dYRgGURShaRqVSoXVaoWmabiui+M4TCYTsiwjyzKq1Srj8RjXdZnNZhwcHDAajXBdl8lkwtPTE47jsFwuKZfLpGlKqVSi0+nQ6/XwPI/xeEwcx5imSZZl7O3tEYYhhmHw/PxMkiQUi0UmkwlKqbxHjUaDMAzxPA/btmm325yentJut1FK8fr6ynw+xzRNOp0OV1dXRFGE4zi8v7/jeR7T6ZRGo4Ft2+zu7tLv92m1WqzXa0zT5OHhgWaziVKK4XCI4zgcHh5yeXlJpVLJ9zYYDLAsi0KhkN8Ty7LQNC3/f8RxzHw+z58/x3Go1+sopQjDEN/3GQ6HzOdz9vf3GY1GJEmC4ziYpkmj0WAwGBBFEeVymW63S7/fJwgCDMPAdV2Ojo7o9XqYpsl6vcb3fW5ubuh2u5ydnVGv11kul1SrVZRSfHx85Od2dnby+399fa3+7RlW8smYEEJsj7xeEEKILZLQFUKILZLQFUKILZLQFUKILZLQFUKILZLQFUKILfoLK7+TJjoyEV8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(f1, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract video features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_all_videos(videos, labels):\n",
    "    num_samples = videos.shape[0] \n",
    "\n",
    "    # `frame_features` are what we will feed to our sequence model.\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, NB_FRAMES, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idv, video in enumerate(videos):\n",
    "        # Extract features from the frames of the current video.\n",
    "        for idf, frame in enumerate(video):\n",
    "            frame_features[idv,idf, :] = feature_extractor.predict(frame[None,:,:])\n",
    "            \n",
    "    return frame_features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the CNN feature map\n",
    "#train_data,train_labels=prepare_all_videos(X_for_classifier,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "#from numpy import savetxt\n",
    "#filename = 'CNN_featuremap_train.npy'\n",
    "#np.save(filename, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"CNN_featuremap_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 30, 1024)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the CNN feature map\n",
    "#test_data,test_labels=prepare_all_videos(Xtest_for_classifier,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "#from numpy import savetxt\n",
    "#filename = 'CNN_featuremap_test.npy'\n",
    "#np.save(filename, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load(\"CNN_featuremap_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 30, 1024)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformer-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=tf.nn.gelu), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    sequence_length = 30\n",
    "    embed_dim = NUM_FEATURES\n",
    "    dense_dim = 4\n",
    "    num_heads = 1\n",
    "    classes = 8\n",
    "\n",
    "    inputs = keras.Input(shape=(None, None))\n",
    "    x = PositionalEmbedding(\n",
    "        sequence_length, embed_dim, name=\"frame_position_embedding\"\n",
    "    )(inputs)\n",
    "    x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_experiment():\n",
    "    filepath = \"./tmp/video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    model = get_compiled_model()\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        validation_split=0.15,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    model.load_weights(filepath)\n",
    "    _, accuracy = model.evaluate(test_data, test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 6.6106 - accuracy: 0.1400\n",
      "Epoch 1: val_loss improved from inf to 4.98335, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 6.6106 - accuracy: 0.1400 - val_loss: 4.9834 - val_accuracy: 0.1111\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 4.4084 - accuracy: 0.1600\n",
      "Epoch 2: val_loss improved from 4.98335 to 2.97988, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 4.4084 - accuracy: 0.1600 - val_loss: 2.9799 - val_accuracy: 0.0741\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.3063 - accuracy: 0.1533\n",
      "Epoch 3: val_loss improved from 2.97988 to 2.43093, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3.3063 - accuracy: 0.1533 - val_loss: 2.4309 - val_accuracy: 0.1481\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.1861 - accuracy: 0.1867\n",
      "Epoch 4: val_loss improved from 2.43093 to 2.19288, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3.1861 - accuracy: 0.1867 - val_loss: 2.1929 - val_accuracy: 0.1111\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.0484 - accuracy: 0.0933\n",
      "Epoch 5: val_loss did not improve from 2.19288\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.0484 - accuracy: 0.0933 - val_loss: 2.3571 - val_accuracy: 0.1481\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.7753 - accuracy: 0.2000\n",
      "Epoch 6: val_loss improved from 2.19288 to 1.94379, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 2.7753 - accuracy: 0.2000 - val_loss: 1.9438 - val_accuracy: 0.4074\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.7892 - accuracy: 0.1600\n",
      "Epoch 7: val_loss did not improve from 1.94379\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7892 - accuracy: 0.1600 - val_loss: 2.1330 - val_accuracy: 0.0741\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.6733 - accuracy: 0.1733\n",
      "Epoch 8: val_loss improved from 1.94379 to 1.79617, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 2.6733 - accuracy: 0.1733 - val_loss: 1.7962 - val_accuracy: 0.4074\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.5400 - accuracy: 0.1867\n",
      "Epoch 9: val_loss did not improve from 1.79617\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.5400 - accuracy: 0.1867 - val_loss: 1.9129 - val_accuracy: 0.2963\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.6049 - accuracy: 0.1733\n",
      "Epoch 10: val_loss improved from 1.79617 to 1.75104, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 2.6049 - accuracy: 0.1733 - val_loss: 1.7510 - val_accuracy: 0.2963\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.5658 - accuracy: 0.2067\n",
      "Epoch 11: val_loss did not improve from 1.75104\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.5658 - accuracy: 0.2067 - val_loss: 1.8712 - val_accuracy: 0.4074\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.4064 - accuracy: 0.2333\n",
      "Epoch 12: val_loss did not improve from 1.75104\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.4064 - accuracy: 0.2333 - val_loss: 1.8224 - val_accuracy: 0.1852\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.3128 - accuracy: 0.2067\n",
      "Epoch 13: val_loss improved from 1.75104 to 1.73611, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 2.3128 - accuracy: 0.2067 - val_loss: 1.7361 - val_accuracy: 0.4074\n",
      "Epoch 14/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2655 - accuracy: 0.2188\n",
      "Epoch 14: val_loss did not improve from 1.73611\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3114 - accuracy: 0.2400 - val_loss: 1.7832 - val_accuracy: 0.4444\n",
      "Epoch 15/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1779 - accuracy: 0.2812\n",
      "Epoch 15: val_loss did not improve from 1.73611\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2059 - accuracy: 0.2667 - val_loss: 1.8063 - val_accuracy: 0.3704\n",
      "Epoch 16/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8066 - accuracy: 0.4375\n",
      "Epoch 16: val_loss did not improve from 1.73611\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8828 - accuracy: 0.3533 - val_loss: 1.8434 - val_accuracy: 0.4444\n",
      "Epoch 17/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6954 - accuracy: 0.4375\n",
      "Epoch 17: val_loss improved from 1.73611 to 1.65592, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.7743 - accuracy: 0.3867 - val_loss: 1.6559 - val_accuracy: 0.4074\n",
      "Epoch 18/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5893 - accuracy: 0.4375\n",
      "Epoch 18: val_loss improved from 1.65592 to 1.64665, saving model to ./tmp\\video_classifier\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 1.9110 - accuracy: 0.3400 - val_loss: 1.6466 - val_accuracy: 0.4815\n",
      "Epoch 19/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1946 - accuracy: 0.2188\n",
      "Epoch 19: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0848 - accuracy: 0.2667 - val_loss: 1.7291 - val_accuracy: 0.3704\n",
      "Epoch 20/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8334 - accuracy: 0.4062\n",
      "Epoch 20: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8615 - accuracy: 0.3600 - val_loss: 1.7147 - val_accuracy: 0.5185\n",
      "Epoch 21/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4050 - accuracy: 0.4688\n",
      "Epoch 21: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6323 - accuracy: 0.4067 - val_loss: 1.9128 - val_accuracy: 0.4444\n",
      "Epoch 22/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4379 - accuracy: 0.4375\n",
      "Epoch 22: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6347 - accuracy: 0.3933 - val_loss: 1.8377 - val_accuracy: 0.3704\n",
      "Epoch 23/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4651 - accuracy: 0.4375\n",
      "Epoch 23: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7131 - accuracy: 0.4533 - val_loss: 1.8960 - val_accuracy: 0.4074\n",
      "Epoch 24/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2861 - accuracy: 0.3750\n",
      "Epoch 24: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7366 - accuracy: 0.4000 - val_loss: 2.3121 - val_accuracy: 0.2222\n",
      "Epoch 25/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7428 - accuracy: 0.4062\n",
      "Epoch 25: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4325 - accuracy: 0.5400 - val_loss: 2.1289 - val_accuracy: 0.3333\n",
      "Epoch 26/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4565 - accuracy: 0.4062\n",
      "Epoch 26: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4335 - accuracy: 0.5133 - val_loss: 2.3644 - val_accuracy: 0.1852\n",
      "Epoch 27/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1070 - accuracy: 0.5625\n",
      "Epoch 27: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2480 - accuracy: 0.5467 - val_loss: 2.2848 - val_accuracy: 0.2593\n",
      "Epoch 28/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0213 - accuracy: 0.5625\n",
      "Epoch 28: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0040 - accuracy: 0.6133 - val_loss: 2.7887 - val_accuracy: 0.0741\n",
      "Epoch 29/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2405 - accuracy: 0.5312\n",
      "Epoch 29: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0564 - accuracy: 0.6267 - val_loss: 3.1495 - val_accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0099 - accuracy: 0.7500\n",
      "Epoch 30: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9014 - accuracy: 0.7267 - val_loss: 3.3834 - val_accuracy: 0.1852\n",
      "Epoch 31/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.7675 - accuracy: 0.7188\n",
      "Epoch 31: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8742 - accuracy: 0.6867 - val_loss: 4.0121 - val_accuracy: 0.2593\n",
      "Epoch 32/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.7446 - accuracy: 0.7500\n",
      "Epoch 32: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8219 - accuracy: 0.7200 - val_loss: 4.5339 - val_accuracy: 0.3333\n",
      "Epoch 33/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.8568 - accuracy: 0.5938\n",
      "Epoch 33: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7801 - accuracy: 0.7000 - val_loss: 5.2570 - val_accuracy: 0.1481\n",
      "Epoch 34/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4476 - accuracy: 0.8750\n",
      "Epoch 34: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6330 - accuracy: 0.7533 - val_loss: 4.5613 - val_accuracy: 0.2963\n",
      "Epoch 35/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4182 - accuracy: 0.8438\n",
      "Epoch 35: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5812 - accuracy: 0.8133 - val_loss: 5.3793 - val_accuracy: 0.1481\n",
      "Epoch 36/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6199 - accuracy: 0.6562\n",
      "Epoch 36: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4416 - accuracy: 0.7800 - val_loss: 5.5301 - val_accuracy: 0.1481\n",
      "Epoch 37/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5980 - accuracy: 0.8125\n",
      "Epoch 37: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4457 - accuracy: 0.8533 - val_loss: 5.1832 - val_accuracy: 0.2222\n",
      "Epoch 38/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1674 - accuracy: 0.9375\n",
      "Epoch 38: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2697 - accuracy: 0.8733 - val_loss: 5.9575 - val_accuracy: 0.1111\n",
      "Epoch 39/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1867 - accuracy: 0.9375\n",
      "Epoch 39: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3024 - accuracy: 0.8867 - val_loss: 5.8356 - val_accuracy: 0.2593\n",
      "Epoch 40/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2788 - accuracy: 0.8750\n",
      "Epoch 40: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4644 - accuracy: 0.8533 - val_loss: 7.7126 - val_accuracy: 0.2222\n",
      "Epoch 41/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1872 - accuracy: 0.9375\n",
      "Epoch 41: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2549 - accuracy: 0.9133 - val_loss: 6.9735 - val_accuracy: 0.1481\n",
      "Epoch 42/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1400 - accuracy: 0.9688\n",
      "Epoch 42: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2681 - accuracy: 0.9067 - val_loss: 7.2527 - val_accuracy: 0.2222\n",
      "Epoch 43/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1506 - accuracy: 0.9375\n",
      "Epoch 43: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3092 - accuracy: 0.9000 - val_loss: 8.2497 - val_accuracy: 0.0741\n",
      "Epoch 44/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1924 - accuracy: 0.9688\n",
      "Epoch 44: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2165 - accuracy: 0.9400 - val_loss: 6.6753 - val_accuracy: 0.1111\n",
      "Epoch 45/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0872 - accuracy: 0.9688\n",
      "Epoch 45: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1502 - accuracy: 0.9467 - val_loss: 7.5613 - val_accuracy: 0.1111\n",
      "Epoch 46/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0603 - accuracy: 0.9688\n",
      "Epoch 46: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1632 - accuracy: 0.9533 - val_loss: 7.5626 - val_accuracy: 0.2222\n",
      "Epoch 47/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0812 - accuracy: 1.0000\n",
      "Epoch 47: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.9533 - val_loss: 7.7370 - val_accuracy: 0.1481\n",
      "Epoch 48/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2432 - accuracy: 0.8750\n",
      "Epoch 48: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1387 - accuracy: 0.9333 - val_loss: 6.6199 - val_accuracy: 0.3333\n",
      "Epoch 49/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0584 - accuracy: 1.0000\n",
      "Epoch 49: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1182 - accuracy: 0.9667 - val_loss: 8.2260 - val_accuracy: 0.1852\n",
      "Epoch 50/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0770 - accuracy: 0.9688\n",
      "Epoch 50: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1163 - accuracy: 0.9600 - val_loss: 7.1112 - val_accuracy: 0.2963\n",
      "Epoch 51/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 51: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2251 - accuracy: 0.9267 - val_loss: 7.0985 - val_accuracy: 0.2222\n",
      "Epoch 52/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1332 - accuracy: 0.9375\n",
      "Epoch 52: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1554 - accuracy: 0.9400 - val_loss: 7.7638 - val_accuracy: 0.2593\n",
      "Epoch 53/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1567 - accuracy: 0.9375\n",
      "Epoch 53: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2695 - accuracy: 0.9000 - val_loss: 7.5188 - val_accuracy: 0.1852\n",
      "Epoch 54/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1023 - accuracy: 0.9688\n",
      "Epoch 54: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4558 - accuracy: 0.8933 - val_loss: 8.1443 - val_accuracy: 0.1481\n",
      "Epoch 55/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2476 - accuracy: 0.9375\n",
      "Epoch 55: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2503 - accuracy: 0.9067 - val_loss: 6.5598 - val_accuracy: 0.3333\n",
      "Epoch 56/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2202 - accuracy: 0.9062\n",
      "Epoch 56: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2549 - accuracy: 0.9133 - val_loss: 6.1156 - val_accuracy: 0.2593\n",
      "Epoch 57/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1795 - accuracy: 0.9688\n",
      "Epoch 57: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1511 - accuracy: 0.9600 - val_loss: 8.1509 - val_accuracy: 0.1481\n",
      "Epoch 58/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1910 - accuracy: 0.9375\n",
      "Epoch 58: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1003 - accuracy: 0.9800 - val_loss: 7.8787 - val_accuracy: 0.3333\n",
      "Epoch 59/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 59: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1330 - accuracy: 0.9533 - val_loss: 8.5254 - val_accuracy: 0.3333\n",
      "Epoch 60/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 60: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1038 - accuracy: 0.9600 - val_loss: 9.3746 - val_accuracy: 0.2222\n",
      "Epoch 61/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 61: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1093 - accuracy: 0.9733 - val_loss: 7.7804 - val_accuracy: 0.2963\n",
      "Epoch 62/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 62: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 7.5733 - val_accuracy: 0.3333\n",
      "Epoch 63/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0495 - accuracy: 0.9688\n",
      "Epoch 63: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0627 - accuracy: 0.9733 - val_loss: 7.4700 - val_accuracy: 0.2593\n",
      "Epoch 64/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0809 - accuracy: 0.9688\n",
      "Epoch 64: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0869 - accuracy: 0.9800 - val_loss: 8.0483 - val_accuracy: 0.2593\n",
      "Epoch 65/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1031 - accuracy: 0.9688\n",
      "Epoch 65: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0730 - accuracy: 0.9733 - val_loss: 7.0308 - val_accuracy: 0.2963\n",
      "Epoch 66/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0648 - accuracy: 1.0000\n",
      "Epoch 66: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1656 - accuracy: 0.9533 - val_loss: 10.2770 - val_accuracy: 0.1481\n",
      "Epoch 67/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2973 - accuracy: 0.9375\n",
      "Epoch 67: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1446 - accuracy: 0.9467 - val_loss: 8.5473 - val_accuracy: 0.3333\n",
      "Epoch 68/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0654 - accuracy: 1.0000\n",
      "Epoch 68: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1051 - accuracy: 0.9667 - val_loss: 8.5230 - val_accuracy: 0.2222\n",
      "Epoch 69/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 69: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2274 - accuracy: 0.9533 - val_loss: 8.0885 - val_accuracy: 0.2222\n",
      "Epoch 70/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 70: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0574 - accuracy: 0.9867 - val_loss: 7.6907 - val_accuracy: 0.3704\n",
      "Epoch 71/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2282 - accuracy: 0.9375\n",
      "Epoch 71: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1266 - accuracy: 0.9667 - val_loss: 8.3302 - val_accuracy: 0.2593\n",
      "Epoch 72/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 72: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0332 - accuracy: 0.9933 - val_loss: 9.0081 - val_accuracy: 0.2593\n",
      "Epoch 73/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 73: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 8.4229 - val_accuracy: 0.1852\n",
      "Epoch 74/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 74: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0171 - accuracy: 0.9933 - val_loss: 8.3548 - val_accuracy: 0.2222\n",
      "Epoch 75/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0738 - accuracy: 0.9688\n",
      "Epoch 75: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0276 - accuracy: 0.9867 - val_loss: 8.4854 - val_accuracy: 0.2593\n",
      "Epoch 76/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 76: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0238 - accuracy: 0.9867 - val_loss: 9.8263 - val_accuracy: 0.1852\n",
      "Epoch 77/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 77: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0446 - accuracy: 0.9800 - val_loss: 8.9107 - val_accuracy: 0.2222\n",
      "Epoch 78/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 78: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0387 - accuracy: 0.9933 - val_loss: 7.7647 - val_accuracy: 0.2963\n",
      "Epoch 79/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 79: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0399 - accuracy: 0.9867 - val_loss: 8.6583 - val_accuracy: 0.2593\n",
      "Epoch 80/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 80: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 8.9183 - val_accuracy: 0.2222\n",
      "Epoch 81/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 81: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 8.8336 - val_accuracy: 0.1852\n",
      "Epoch 82/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 82: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0331 - accuracy: 0.9867 - val_loss: 9.9941 - val_accuracy: 0.2222\n",
      "Epoch 83/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0898 - accuracy: 0.9688\n",
      "Epoch 83: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 8.1311 - val_accuracy: 0.2963\n",
      "Epoch 84/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0344 - accuracy: 0.9688\n",
      "Epoch 84: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0498 - accuracy: 0.9867 - val_loss: 8.2672 - val_accuracy: 0.2963\n",
      "Epoch 85/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 85: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0279 - accuracy: 0.9867 - val_loss: 9.0323 - val_accuracy: 0.2222\n",
      "Epoch 86/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0626 - accuracy: 0.9688\n",
      "Epoch 86: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 8.9416 - val_accuracy: 0.2222\n",
      "Epoch 87/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0962 - accuracy: 0.9688\n",
      "Epoch 87: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0545 - accuracy: 0.9800 - val_loss: 8.5126 - val_accuracy: 0.2222\n",
      "Epoch 88/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 88: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0447 - accuracy: 0.9867 - val_loss: 10.3392 - val_accuracy: 0.2222\n",
      "Epoch 89/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 89: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0155 - accuracy: 0.9933 - val_loss: 8.5601 - val_accuracy: 0.2963\n",
      "Epoch 90/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 90: val_loss did not improve from 1.64665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0374 - accuracy: 0.9800 - val_loss: 9.0505 - val_accuracy: 0.2593\n",
      "Epoch 91/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 91: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0826 - accuracy: 0.9667 - val_loss: 8.3096 - val_accuracy: 0.1852\n",
      "Epoch 92/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0970 - accuracy: 0.9688\n",
      "Epoch 92: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0879 - accuracy: 0.9800 - val_loss: 9.6937 - val_accuracy: 0.2593\n",
      "Epoch 93/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 93: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 8.7164 - val_accuracy: 0.2963\n",
      "Epoch 94/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0833 - accuracy: 0.9688\n",
      "Epoch 94: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0329 - accuracy: 0.9867 - val_loss: 7.2171 - val_accuracy: 0.2963\n",
      "Epoch 95/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1217 - accuracy: 0.9688\n",
      "Epoch 95: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0472 - accuracy: 0.9800 - val_loss: 8.7566 - val_accuracy: 0.2963\n",
      "Epoch 96/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 96: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 9.6253 - val_accuracy: 0.2593\n",
      "Epoch 97/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0424 - accuracy: 0.9688\n",
      "Epoch 97: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0164 - accuracy: 0.9933 - val_loss: 8.9419 - val_accuracy: 0.1852\n",
      "Epoch 98/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 98: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9933 - val_loss: 8.6872 - val_accuracy: 0.2963\n",
      "Epoch 99/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 99: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 8.7400 - val_accuracy: 0.2593\n",
      "Epoch 100/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 100: val_loss did not improve from 1.64665\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 8.3662 - val_accuracy: 0.2963\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.2233 - accuracy: 0.2100\n",
      "Test accuracy: 21.0%\n"
     ]
    }
   ],
   "source": [
    "trained_model = run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    " print(tf. __version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_test, labels_test  = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videos_test, labels_test=filter(filters,videos_test, labels_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22192/4015005363.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbuiltx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuilty\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m290\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideos_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "builtx, builty= create_dataset(290,300, videos_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_for_classifier = np.array(builtx)\n",
    "ytest_for_classifier = np.array(builty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_for_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_batch=Xtest_for_classifier\n",
    "rgb_batch = np.repeat(grayscale_batch[..., np.newaxis], 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_for_classifier=func(ytest_for_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_for_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_for_classifier= rgb_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_for_classifier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(Xtest_for_classifier, ytest_for_classifier)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(Xtest_for_classifier)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_for_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "con_mat = confusion_matrix(ytest_for_classifier, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=con_mat)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(ytest_for_classifier, preds,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bovine-gpu",
   "language": "python",
   "name": "bovine-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
